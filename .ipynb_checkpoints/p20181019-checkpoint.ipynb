{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepDream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import inception_v3\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_learning_phase(0)\n",
    "\n",
    "model = inception_v3.InceptionV3(weights='imagenet',\n",
    "                                 include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, None, None, 3 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, None, 3 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None, None, 3 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, None, None, 3 9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, None, 3 96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, None, None, 3 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, None, None, 6 18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, None, 6 192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, None, None, 6 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, None, None, 6 0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, None, None, 8 5120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, None, None, 8 240         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, None, None, 8 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, None, None, 1 138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, None, None, 1 576         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, None, None, 1 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, None, None, 1 0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, None, None, 6 12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, None, None, 6 192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, None, None, 6 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, None, None, 4 9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, None, None, 9 55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, None, None, 4 144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, None, None, 9 288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, None, None, 4 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, None, None, 9 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, None, None, 1 0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, None, None, 6 12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, None, None, 6 76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, None, None, 9 82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, None, None, 3 6144        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, None, None, 6 192         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, None, None, 6 192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, None, None, 9 288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, None, None, 3 96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, None, None, 6 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, None, None, 6 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, None, None, 9 0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, None, None, 3 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, None, None, 2 0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, None, None, 6 16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, None, None, 6 192         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, None, None, 6 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, None, None, 4 12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, None, None, 9 55296       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, None, None, 4 144         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, None, None, 9 288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, None, None, 4 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, None, None, 9 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, None, None, 2 0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, None, None, 6 16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, None, None, 6 76800       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, None, None, 9 82944       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, None, None, 6 16384       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, None, None, 6 192         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, None, None, 6 192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, None, None, 9 288         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, None, None, 6 192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, None, None, 6 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, None, None, 6 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, None, None, 9 0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, None, None, 6 0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, None, None, 2 0           activation_13[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, None, None, 6 18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, None, None, 6 192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, None, None, 6 0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, None, None, 4 13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, None, None, 9 55296       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, None, None, 4 144         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, None, None, 9 288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, None, None, 4 0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, None, None, 9 0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, None, None, 2 0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, None, None, 6 18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, None, None, 6 76800       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, None, None, 9 82944       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, None, None, 6 18432       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, None, None, 6 192         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, None, None, 6 192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, None, None, 9 288         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, None, None, 6 192         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, None, None, 6 0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, None, None, 6 0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, None, None, 9 0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, None, None, 6 0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, None, None, 2 0           activation_20[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, None, None, 6 18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, None, None, 6 192         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, None, None, 6 0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, None, None, 9 55296       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, None, None, 9 288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, None, None, 9 0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, None, None, 3 995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, None, None, 9 82944       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, None, None, 3 1152        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, None, None, 9 288         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, None, None, 3 0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, None, None, 9 0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, None, None, 2 0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, None, None, 7 0           activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, None, None, 1 98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, None, None, 1 384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, None, None, 1 0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, None, None, 1 114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, None, None, 1 384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, None, None, 1 0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, None, None, 1 98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, None, None, 1 114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, None, None, 1 384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, None, None, 1 384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, None, None, 1 0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, None, None, 1 0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, None, None, 1 114688      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, None, None, 1 114688      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, None, None, 1 384         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, None, None, 1 384         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, None, None, 1 0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, None, None, 1 0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, None, None, 7 0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, None, None, 1 147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, None, None, 1 172032      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, None, None, 1 172032      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, None, None, 1 576         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, None, None, 1 576         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, None, None, 1 576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, None, None, 1 576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, None, None, 1 0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, None, None, 1 0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, None, None, 1 0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, None, None, 1 0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, None, None, 7 0           activation_31[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, None, None, 1 122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, None, None, 1 480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, None, None, 1 0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, None, None, 1 179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, None, None, 1 480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, None, None, 1 0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, None, None, 1 122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, None, None, 1 179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, None, None, 1 480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, None, None, 1 480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, None, None, 1 0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, None, None, 1 0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, None, None, 1 179200      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, None, None, 1 179200      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, None, None, 1 480         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, None, None, 1 480         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, None, None, 1 0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, None, None, 1 0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, None, None, 7 0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, None, None, 1 147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, None, None, 1 215040      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, None, None, 1 215040      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, None, None, 1 576         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, None, None, 1 576         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, None, None, 1 576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, None, None, 1 576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, None, None, 1 0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, None, None, 1 0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, None, None, 1 0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, None, None, 1 0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, None, None, 7 0           activation_41[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, None, None, 1 122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, None, None, 1 480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, None, None, 1 0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, None, None, 1 179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, None, None, 1 480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, None, None, 1 0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, None, None, 1 122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, None, None, 1 179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, None, None, 1 480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, None, None, 1 480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, None, None, 1 0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, None, None, 1 0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, None, None, 1 179200      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, None, None, 1 179200      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, None, None, 1 480         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, None, None, 1 480         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, None, None, 1 0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, None, None, 1 0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, None, None, 7 0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, None, None, 1 147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, None, None, 1 215040      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, None, None, 1 215040      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, None, None, 1 576         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, None, None, 1 576         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, None, None, 1 576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, None, None, 1 576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, None, None, 1 0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, None, None, 1 0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, None, None, 1 0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, None, None, 1 0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, None, None, 7 0           activation_51[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, None, None, 1 576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, None, None, 1 0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, None, None, 1 258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, None, None, 1 576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, None, None, 1 0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, None, None, 1 258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, None, None, 1 576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, None, None, 1 576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, None, None, 1 0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, None, None, 1 0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, None, None, 1 258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, None, None, 1 258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, None, None, 1 576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, None, None, 1 576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, None, None, 1 0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, None, None, 1 0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, None, None, 7 0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, None, None, 1 258048      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, None, None, 1 258048      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, None, None, 1 576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, None, None, 1 576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, None, None, 1 576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, None, None, 1 576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, None, None, 1 0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, None, None, 1 0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, None, None, 1 0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, None, None, 1 0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, None, None, 7 0           activation_61[0][0]              \n",
      "                                                                 activation_64[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "                                                                 activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, None, None, 1 147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, None, None, 1 576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, None, None, 1 0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, None, None, 1 258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, None, None, 1 576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, None, None, 1 0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, None, None, 1 147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, None, None, 1 258048      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, None, None, 1 576         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, None, None, 1 576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, None, None, 1 0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, None, None, 1 0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, None, None, 3 552960      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, None, None, 1 331776      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, None, None, 3 960         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, None, None, 1 576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, None, None, 3 0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, None, None, 1 0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, None, None, 7 0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, None, None, 1 0           activation_72[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, None, None, 4 573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, None, None, 4 1344        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, None, None, 4 0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, None, None, 3 491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, None, None, 3 1548288     activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, None, None, 3 1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, None, None, 3 1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, None, None, 3 0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, None, None, 3 0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, None, None, 3 442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, None, None, 3 442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, None, None, 3 442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, None, None, 3 442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, None, None, 1 0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, None, None, 3 409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, None, None, 3 1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, None, None, 3 1152        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, None, None, 3 1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, None, None, 3 1152        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, None, None, 1 245760      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, None, None, 3 960         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, None, None, 3 0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, None, None, 3 0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, None, None, 3 0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, None, None, 3 0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, None, None, 1 576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, None, None, 3 0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, None, None, 7 0           activation_79[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, None, 7 0           activation_83[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, None, None, 1 0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, None, None, 2 0           activation_77[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, None, None, 4 917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, None, None, 4 1344        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, None, None, 4 0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, None, None, 3 786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, None, None, 3 1548288     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, None, None, 3 1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, None, None, 3 1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, None, None, 3 0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, None, None, 3 0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, None, None, 3 442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, None, None, 3 442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, None, None, 3 442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, None, None, 3 442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, None, None, 2 0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, None, None, 3 655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, None, None, 3 1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, None, None, 3 1152        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, None, None, 3 1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, None, None, 3 1152        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, None, None, 1 393216      average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, None, None, 3 960         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, None, None, 3 0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, None, None, 3 0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, None, None, 3 0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, None, None, 3 0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, None, None, 1 576         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, None, None, 3 0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, None, None, 7 0           activation_88[0][0]              \n",
      "                                                                 activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, None, None, 7 0           activation_92[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, None, None, 1 0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, None, None, 2 0           activation_86[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_94[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 21,768,352\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_contributions = {\n",
    "    'mixed2': 0.2,\n",
    "    'mixed3': 3.,\n",
    "    'activation_94': 2.,\n",
    "    'conv2d_93': 0.5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation_1': <keras.layers.core.Activation at 0x21c87fa25f8>,\n",
       " 'activation_10': <keras.layers.core.Activation at 0x21c896b7240>,\n",
       " 'activation_11': <keras.layers.core.Activation at 0x21c8976e240>,\n",
       " 'activation_12': <keras.layers.core.Activation at 0x21c897b90b8>,\n",
       " 'activation_13': <keras.layers.core.Activation at 0x21c89892828>,\n",
       " 'activation_14': <keras.layers.core.Activation at 0x21c8993bc88>,\n",
       " 'activation_15': <keras.layers.core.Activation at 0x21c899f9f28>,\n",
       " 'activation_16': <keras.layers.core.Activation at 0x21c89af27b8>,\n",
       " 'activation_17': <keras.layers.core.Activation at 0x21c89b5e2b0>,\n",
       " 'activation_18': <keras.layers.core.Activation at 0x21c89c1def0>,\n",
       " 'activation_19': <keras.layers.core.Activation at 0x21c89d15438>,\n",
       " 'activation_2': <keras.layers.core.Activation at 0x21c88007940>,\n",
       " 'activation_20': <keras.layers.core.Activation at 0x21c89d93f28>,\n",
       " 'activation_21': <keras.layers.core.Activation at 0x21c89ea3f28>,\n",
       " 'activation_22': <keras.layers.core.Activation at 0x21c89f77278>,\n",
       " 'activation_23': <keras.layers.core.Activation at 0x21c89f9a4e0>,\n",
       " 'activation_24': <keras.layers.core.Activation at 0x21c8a05e748>,\n",
       " 'activation_25': <keras.layers.core.Activation at 0x21c8a19afd0>,\n",
       " 'activation_26': <keras.layers.core.Activation at 0x21c8a2174a8>,\n",
       " 'activation_27': <keras.layers.core.Activation at 0x21c8a27dfd0>,\n",
       " 'activation_28': <keras.layers.core.Activation at 0x21c8a370a90>,\n",
       " 'activation_29': <keras.layers.core.Activation at 0x21c8a479048>,\n",
       " 'activation_3': <keras.layers.core.Activation at 0x21c891bd240>,\n",
       " 'activation_30': <keras.layers.core.Activation at 0x21c8a5078d0>,\n",
       " 'activation_31': <keras.layers.core.Activation at 0x21c8a592a90>,\n",
       " 'activation_32': <keras.layers.core.Activation at 0x21c8b620940>,\n",
       " 'activation_33': <keras.layers.core.Activation at 0x21c8b6fca90>,\n",
       " 'activation_34': <keras.layers.core.Activation at 0x21c8b7bb940>,\n",
       " 'activation_35': <keras.layers.core.Activation at 0x21c8b843978>,\n",
       " 'activation_36': <keras.layers.core.Activation at 0x21c8b920ac8>,\n",
       " 'activation_37': <keras.layers.core.Activation at 0x21c8b9e0f60>,\n",
       " 'activation_38': <keras.layers.core.Activation at 0x21c8ba2f9e8>,\n",
       " 'activation_39': <keras.layers.core.Activation at 0x21c8bb6a240>,\n",
       " 'activation_4': <keras.layers.core.Activation at 0x21c89262748>,\n",
       " 'activation_40': <keras.layers.core.Activation at 0x21c8bba7128>,\n",
       " 'activation_41': <keras.layers.core.Activation at 0x21c8bc87390>,\n",
       " 'activation_42': <keras.layers.core.Activation at 0x21c8bd469b0>,\n",
       " 'activation_43': <keras.layers.core.Activation at 0x21c8be24b00>,\n",
       " 'activation_44': <keras.layers.core.Activation at 0x21c8bedff60>,\n",
       " 'activation_45': <keras.layers.core.Activation at 0x21c8bf699e8>,\n",
       " 'activation_46': <keras.layers.core.Activation at 0x21c8c04cda0>,\n",
       " 'activation_47': <keras.layers.core.Activation at 0x21c8c108f98>,\n",
       " 'activation_48': <keras.layers.core.Activation at 0x21c8c15bf28>,\n",
       " 'activation_49': <keras.layers.core.Activation at 0x21c8c296278>,\n",
       " 'activation_5': <keras.layers.core.Activation at 0x21c892e1e80>,\n",
       " 'activation_50': <keras.layers.core.Activation at 0x21c8c317470>,\n",
       " 'activation_51': <keras.layers.core.Activation at 0x21c8c3e6860>,\n",
       " 'activation_52': <keras.layers.core.Activation at 0x21c8c470a90>,\n",
       " 'activation_53': <keras.layers.core.Activation at 0x21c8c579048>,\n",
       " 'activation_54': <keras.layers.core.Activation at 0x21c8c6078d0>,\n",
       " 'activation_55': <keras.layers.core.Activation at 0x21c8c694a90>,\n",
       " 'activation_56': <keras.layers.core.Activation at 0x21c8c661e80>,\n",
       " 'activation_57': <keras.layers.core.Activation at 0x21c8c8308d0>,\n",
       " 'activation_58': <keras.layers.core.Activation at 0x21c8c885f98>,\n",
       " 'activation_59': <keras.layers.core.Activation at 0x21c8c947f28>,\n",
       " 'activation_6': <keras.layers.core.Activation at 0x21c87ff99e8>,\n",
       " 'activation_60': <keras.layers.core.Activation at 0x21c8ca40c88>,\n",
       " 'activation_61': <keras.layers.core.Activation at 0x21c8caa97b8>,\n",
       " 'activation_62': <keras.layers.core.Activation at 0x21c8cbcfef0>,\n",
       " 'activation_63': <keras.layers.core.Activation at 0x21c8cca5278>,\n",
       " 'activation_64': <keras.layers.core.Activation at 0x21c8dd03978>,\n",
       " 'activation_65': <keras.layers.core.Activation at 0x21c8ddc5e48>,\n",
       " 'activation_66': <keras.layers.core.Activation at 0x21c8de99fd0>,\n",
       " 'activation_67': <keras.layers.core.Activation at 0x21c8df279b0>,\n",
       " 'activation_68': <keras.layers.core.Activation at 0x21c8dfda208>,\n",
       " 'activation_69': <keras.layers.core.Activation at 0x21c8e0404a8>,\n",
       " 'activation_7': <keras.layers.core.Activation at 0x21c89438438>,\n",
       " 'activation_70': <keras.layers.core.Activation at 0x21c8e0e10b8>,\n",
       " 'activation_71': <keras.layers.core.Activation at 0x21c8e1bbf60>,\n",
       " 'activation_72': <keras.layers.core.Activation at 0x21c8e2bd208>,\n",
       " 'activation_73': <keras.layers.core.Activation at 0x21c8e323860>,\n",
       " 'activation_74': <keras.layers.core.Activation at 0x21c8e42f9b0>,\n",
       " 'activation_75': <keras.layers.core.Activation at 0x21c8e4e2240>,\n",
       " 'activation_76': <keras.layers.core.Activation at 0x21c8e59a240>,\n",
       " 'activation_77': <keras.layers.core.Activation at 0x21c8e603c50>,\n",
       " 'activation_78': <keras.layers.core.Activation at 0x21c8e7016d8>,\n",
       " 'activation_79': <keras.layers.core.Activation at 0x21c8e76be80>,\n",
       " 'activation_8': <keras.layers.core.Activation at 0x21c894fbf98>,\n",
       " 'activation_80': <keras.layers.core.Activation at 0x21c8e77f358>,\n",
       " 'activation_81': <keras.layers.core.Activation at 0x21c8e85f5c0>,\n",
       " 'activation_82': <keras.layers.core.Activation at 0x21c8e9ec240>,\n",
       " 'activation_83': <keras.layers.core.Activation at 0x21c8ea53f98>,\n",
       " 'activation_84': <keras.layers.core.Activation at 0x21c8eb4c8d0>,\n",
       " 'activation_85': <keras.layers.core.Activation at 0x21c8ebeb6a0>,\n",
       " 'activation_86': <keras.layers.core.Activation at 0x21c8ecaaa20>,\n",
       " 'activation_87': <keras.layers.core.Activation at 0x21c8ed056d8>,\n",
       " 'activation_88': <keras.layers.core.Activation at 0x21c8ee47a20>,\n",
       " 'activation_89': <keras.layers.core.Activation at 0x21c8ee9b2b0>,\n",
       " 'activation_9': <keras.layers.core.Activation at 0x21c895f18d0>,\n",
       " 'activation_90': <keras.layers.core.Activation at 0x21c8ef5efd0>,\n",
       " 'activation_91': <keras.layers.core.Activation at 0x21c8f06db00>,\n",
       " 'activation_92': <keras.layers.core.Activation at 0x21c8f129908>,\n",
       " 'activation_93': <keras.layers.core.Activation at 0x21c8f196eb8>,\n",
       " 'activation_94': <keras.layers.core.Activation at 0x21c8f240550>,\n",
       " 'average_pooling2d_1': <keras.layers.pooling.AveragePooling2D at 0x21c8974eeb8>,\n",
       " 'average_pooling2d_2': <keras.layers.pooling.AveragePooling2D at 0x21c89c1d470>,\n",
       " 'average_pooling2d_3': <keras.layers.pooling.AveragePooling2D at 0x21c8a11de10>,\n",
       " 'average_pooling2d_4': <keras.layers.pooling.AveragePooling2D at 0x21c8baed8d0>,\n",
       " 'average_pooling2d_5': <keras.layers.pooling.AveragePooling2D at 0x21c8c21add8>,\n",
       " 'average_pooling2d_6': <keras.layers.pooling.AveragePooling2D at 0x21c8c9478d0>,\n",
       " 'average_pooling2d_7': <keras.layers.pooling.AveragePooling2D at 0x21c8e040198>,\n",
       " 'average_pooling2d_8': <keras.layers.pooling.AveragePooling2D at 0x21c8eb0bef0>,\n",
       " 'average_pooling2d_9': <keras.layers.pooling.AveragePooling2D at 0x21c8f17ecc0>,\n",
       " 'batch_normalization_1': <keras.layers.normalization.BatchNormalization at 0x21c87fa24a8>,\n",
       " 'batch_normalization_10': <keras.layers.normalization.BatchNormalization at 0x21c8965c860>,\n",
       " 'batch_normalization_11': <keras.layers.normalization.BatchNormalization at 0x21c8972ef60>,\n",
       " 'batch_normalization_12': <keras.layers.normalization.BatchNormalization at 0x21c8980f3c8>,\n",
       " 'batch_normalization_13': <keras.layers.normalization.BatchNormalization at 0x21c898cfc18>,\n",
       " 'batch_normalization_14': <keras.layers.normalization.BatchNormalization at 0x21c8993b630>,\n",
       " 'batch_normalization_15': <keras.layers.normalization.BatchNormalization at 0x21c89a4b080>,\n",
       " 'batch_normalization_16': <keras.layers.normalization.BatchNormalization at 0x21c89acb630>,\n",
       " 'batch_normalization_17': <keras.layers.normalization.BatchNormalization at 0x21c89b73ef0>,\n",
       " 'batch_normalization_18': <keras.layers.normalization.BatchNormalization at 0x21c89c6e128>,\n",
       " 'batch_normalization_19': <keras.layers.normalization.BatchNormalization at 0x21c89d28a58>,\n",
       " 'batch_normalization_2': <keras.layers.normalization.BatchNormalization at 0x21c8801c0b8>,\n",
       " 'batch_normalization_20': <keras.layers.normalization.BatchNormalization at 0x21c89dd14a8>,\n",
       " 'batch_normalization_21': <keras.layers.normalization.BatchNormalization at 0x21c89e50dd8>,\n",
       " 'batch_normalization_22': <keras.layers.normalization.BatchNormalization at 0x21c89f0e940>,\n",
       " 'batch_normalization_23': <keras.layers.normalization.BatchNormalization at 0x21c89fb42e8>,\n",
       " 'batch_normalization_24': <keras.layers.normalization.BatchNormalization at 0x21c8a072048>,\n",
       " 'batch_normalization_25': <keras.layers.normalization.BatchNormalization at 0x21c8a093e10>,\n",
       " 'batch_normalization_26': <keras.layers.normalization.BatchNormalization at 0x21c8a2279b0>,\n",
       " 'batch_normalization_27': <keras.layers.normalization.BatchNormalization at 0x21c8a2b1f28>,\n",
       " 'batch_normalization_28': <keras.layers.normalization.BatchNormalization at 0x21c8a352a20>,\n",
       " 'batch_normalization_29': <keras.layers.normalization.BatchNormalization at 0x21c8a417d68>,\n",
       " 'batch_normalization_3': <keras.layers.normalization.BatchNormalization at 0x21c89181630>,\n",
       " 'batch_normalization_30': <keras.layers.normalization.BatchNormalization at 0x21c8a4a2e10>,\n",
       " 'batch_normalization_31': <keras.layers.normalization.BatchNormalization at 0x21c8a55fe80>,\n",
       " 'batch_normalization_32': <keras.layers.normalization.BatchNormalization at 0x21c8b6205f8>,\n",
       " 'batch_normalization_33': <keras.layers.normalization.BatchNormalization at 0x21c8b6c2518>,\n",
       " 'batch_normalization_34': <keras.layers.normalization.BatchNormalization at 0x21c8b755390>,\n",
       " 'batch_normalization_35': <keras.layers.normalization.BatchNormalization at 0x21c8b843630>,\n",
       " 'batch_normalization_36': <keras.layers.normalization.BatchNormalization at 0x21c8b8e5e80>,\n",
       " 'batch_normalization_37': <keras.layers.normalization.BatchNormalization at 0x21c8b9788d0>,\n",
       " 'batch_normalization_38': <keras.layers.normalization.BatchNormalization at 0x21c8ba2f860>,\n",
       " 'batch_normalization_39': <keras.layers.normalization.BatchNormalization at 0x21c8bb038d0>,\n",
       " 'batch_normalization_4': <keras.layers.normalization.BatchNormalization at 0x21c89222b70>,\n",
       " 'batch_normalization_40': <keras.layers.normalization.BatchNormalization at 0x21c8bb8da20>,\n",
       " 'batch_normalization_41': <keras.layers.normalization.BatchNormalization at 0x21c8bc52dd8>,\n",
       " 'batch_normalization_42': <keras.layers.normalization.BatchNormalization at 0x21c8bd46668>,\n",
       " 'batch_normalization_43': <keras.layers.normalization.BatchNormalization at 0x21c8bdeac88>,\n",
       " 'batch_normalization_44': <keras.layers.normalization.BatchNormalization at 0x21c8be78d68>,\n",
       " 'batch_normalization_45': <keras.layers.normalization.BatchNormalization at 0x21c8bf696a0>,\n",
       " 'batch_normalization_46': <keras.layers.normalization.BatchNormalization at 0x21c8c012cc0>,\n",
       " 'batch_normalization_47': <keras.layers.normalization.BatchNormalization at 0x21c8c0a1da0>,\n",
       " 'batch_normalization_48': <keras.layers.normalization.BatchNormalization at 0x21c8c171be0>,\n",
       " 'batch_normalization_49': <keras.layers.normalization.BatchNormalization at 0x21c8c22e940>,\n",
       " 'batch_normalization_5': <keras.layers.normalization.BatchNormalization at 0x21c892fe6d8>,\n",
       " 'batch_normalization_50': <keras.layers.normalization.BatchNormalization at 0x21c8c2f4550>,\n",
       " 'batch_normalization_51': <keras.layers.normalization.BatchNormalization at 0x21c8c37ddd8>,\n",
       " 'batch_normalization_52': <keras.layers.normalization.BatchNormalization at 0x21c8c453a20>,\n",
       " 'batch_normalization_53': <keras.layers.normalization.BatchNormalization at 0x21c8c516d68>,\n",
       " 'batch_normalization_54': <keras.layers.normalization.BatchNormalization at 0x21c8c5a2e10>,\n",
       " 'batch_normalization_55': <keras.layers.normalization.BatchNormalization at 0x21c8c6767f0>,\n",
       " 'batch_normalization_56': <keras.layers.normalization.BatchNormalization at 0x21c8c737dd8>,\n",
       " 'batch_normalization_57': <keras.layers.normalization.BatchNormalization at 0x21c8c7c8dd8>,\n",
       " 'batch_normalization_58': <keras.layers.normalization.BatchNormalization at 0x21c8c89acf8>,\n",
       " 'batch_normalization_59': <keras.layers.normalization.BatchNormalization at 0x21c8c999f98>,\n",
       " 'batch_normalization_6': <keras.layers.normalization.BatchNormalization at 0x21c88001cc0>,\n",
       " 'batch_normalization_60': <keras.layers.normalization.BatchNormalization at 0x21c8ca54a20>,\n",
       " 'batch_normalization_61': <keras.layers.normalization.BatchNormalization at 0x21c8cadfa90>,\n",
       " 'batch_normalization_62': <keras.layers.normalization.BatchNormalization at 0x21c8cb7d7b8>,\n",
       " 'batch_normalization_63': <keras.layers.normalization.BatchNormalization at 0x21c8cc3e8d0>,\n",
       " 'batch_normalization_64': <keras.layers.normalization.BatchNormalization at 0x21c8cce1710>,\n",
       " 'batch_normalization_65': <keras.layers.normalization.BatchNormalization at 0x21c8dd75ef0>,\n",
       " 'batch_normalization_66': <keras.layers.normalization.BatchNormalization at 0x21c8dd5db70>,\n",
       " 'batch_normalization_67': <keras.layers.normalization.BatchNormalization at 0x21c8def5550>,\n",
       " 'batch_normalization_68': <keras.layers.normalization.BatchNormalization at 0x21c8df7e860>,\n",
       " 'batch_normalization_69': <keras.layers.normalization.BatchNormalization at 0x21c8e093198>,\n",
       " 'batch_normalization_7': <keras.layers.normalization.BatchNormalization at 0x21c89438518>,\n",
       " 'batch_normalization_70': <keras.layers.normalization.BatchNormalization at 0x21c8e14fa90>,\n",
       " 'batch_normalization_71': <keras.layers.normalization.BatchNormalization at 0x21c8e1fa4e0>,\n",
       " 'batch_normalization_72': <keras.layers.normalization.BatchNormalization at 0x21c8e260860>,\n",
       " 'batch_normalization_73': <keras.layers.normalization.BatchNormalization at 0x21c8e323a20>,\n",
       " 'batch_normalization_74': <keras.layers.normalization.BatchNormalization at 0x21c8e3fb588>,\n",
       " 'batch_normalization_75': <keras.layers.normalization.BatchNormalization at 0x21c8e487860>,\n",
       " 'batch_normalization_76': <keras.layers.normalization.BatchNormalization at 0x21c8e55cf60>,\n",
       " 'batch_normalization_77': <keras.layers.normalization.BatchNormalization at 0x21c8e603e80>,\n",
       " 'batch_normalization_78': <keras.layers.normalization.BatchNormalization at 0x21c8e6e0550>,\n",
       " 'batch_normalization_79': <keras.layers.normalization.BatchNormalization at 0x21c8e77f7f0>,\n",
       " 'batch_normalization_8': <keras.layers.normalization.BatchNormalization at 0x21c8954b198>,\n",
       " 'batch_normalization_80': <keras.layers.normalization.BatchNormalization at 0x21c8e82c780>,\n",
       " 'batch_normalization_81': <keras.layers.normalization.BatchNormalization at 0x21c8e8c7eb8>,\n",
       " 'batch_normalization_82': <keras.layers.normalization.BatchNormalization at 0x21c8e98f828>,\n",
       " 'batch_normalization_83': <keras.layers.normalization.BatchNormalization at 0x21c8eaa3198>,\n",
       " 'batch_normalization_84': <keras.layers.normalization.BatchNormalization at 0x21c8eb28e80>,\n",
       " 'batch_normalization_85': <keras.layers.normalization.BatchNormalization at 0x21c8ebb9f98>,\n",
       " 'batch_normalization_86': <keras.layers.normalization.BatchNormalization at 0x21c8ec76320>,\n",
       " 'batch_normalization_87': <keras.layers.normalization.BatchNormalization at 0x21c8ed4bef0>,\n",
       " 'batch_normalization_88': <keras.layers.normalization.BatchNormalization at 0x21c8ee0e668>,\n",
       " 'batch_normalization_89': <keras.layers.normalization.BatchNormalization at 0x21c8ee9b518>,\n",
       " 'batch_normalization_9': <keras.layers.normalization.BatchNormalization at 0x21c895cee80>,\n",
       " 'batch_normalization_90': <keras.layers.normalization.BatchNormalization at 0x21c8ef5ee10>,\n",
       " 'batch_normalization_91': <keras.layers.normalization.BatchNormalization at 0x21c8f032dd8>,\n",
       " 'batch_normalization_92': <keras.layers.normalization.BatchNormalization at 0x21c8f0f5f28>,\n",
       " 'batch_normalization_93': <keras.layers.normalization.BatchNormalization at 0x21c8f196978>,\n",
       " 'batch_normalization_94': <keras.layers.normalization.BatchNormalization at 0x21c8f2bbeb8>,\n",
       " 'concatenate_1': <keras.layers.merge.Concatenate at 0x21c8eb0b438>,\n",
       " 'concatenate_2': <keras.layers.merge.Concatenate at 0x21c8f20f7f0>,\n",
       " 'conv2d_1': <keras.layers.convolutional.Conv2D at 0x21c87fa23c8>,\n",
       " 'conv2d_10': <keras.layers.convolutional.Conv2D at 0x21c895b2438>,\n",
       " 'conv2d_11': <keras.layers.convolutional.Conv2D at 0x21c896eb5f8>,\n",
       " 'conv2d_12': <keras.layers.convolutional.Conv2D at 0x21c897b9eb8>,\n",
       " 'conv2d_13': <keras.layers.convolutional.Conv2D at 0x21c89851e48>,\n",
       " 'conv2d_14': <keras.layers.convolutional.Conv2D at 0x21c8990beb8>,\n",
       " 'conv2d_15': <keras.layers.convolutional.Conv2D at 0x21c89a0df28>,\n",
       " 'conv2d_16': <keras.layers.convolutional.Conv2D at 0x21c899f9940>,\n",
       " 'conv2d_17': <keras.layers.convolutional.Conv2D at 0x21c89bb95c0>,\n",
       " 'conv2d_18': <keras.layers.convolutional.Conv2D at 0x21c89bea2e8>,\n",
       " 'conv2d_19': <keras.layers.convolutional.Conv2D at 0x21c89cbbe80>,\n",
       " 'conv2d_2': <keras.layers.convolutional.Conv2D at 0x21c87fa2128>,\n",
       " 'conv2d_20': <keras.layers.convolutional.Conv2D at 0x21c89d50e48>,\n",
       " 'conv2d_21': <keras.layers.convolutional.Conv2D at 0x21c89de5710>,\n",
       " 'conv2d_22': <keras.layers.convolutional.Conv2D at 0x21c89ecba58>,\n",
       " 'conv2d_23': <keras.layers.convolutional.Conv2D at 0x21c89efcdd8>,\n",
       " 'conv2d_24': <keras.layers.convolutional.Conv2D at 0x21c89ff76d8>,\n",
       " 'conv2d_25': <keras.layers.convolutional.Conv2D at 0x21c8a0ee518>,\n",
       " 'conv2d_26': <keras.layers.convolutional.Conv2D at 0x21c8a151be0>,\n",
       " 'conv2d_27': <keras.layers.convolutional.Conv2D at 0x21c8a24ed30>,\n",
       " 'conv2d_28': <keras.layers.convolutional.Conv2D at 0x21c8a2e55f8>,\n",
       " 'conv2d_29': <keras.layers.convolutional.Conv2D at 0x21c8a3cbf60>,\n",
       " 'conv2d_3': <keras.layers.convolutional.Conv2D at 0x21c8913f7b8>,\n",
       " 'conv2d_30': <keras.layers.convolutional.Conv2D at 0x21c8a3fe9e8>,\n",
       " 'conv2d_31': <keras.layers.convolutional.Conv2D at 0x21c8a4f65f8>,\n",
       " 'conv2d_32': <keras.layers.convolutional.Conv2D at 0x21c8b645fd0>,\n",
       " 'conv2d_33': <keras.layers.convolutional.Conv2D at 0x21c8b67af60>,\n",
       " 'conv2d_34': <keras.layers.convolutional.Conv2D at 0x21c8b6e4a58>,\n",
       " 'conv2d_35': <keras.layers.convolutional.Conv2D at 0x21c8b7e0898>,\n",
       " 'conv2d_36': <keras.layers.convolutional.Conv2D at 0x21c8b89ff60>,\n",
       " 'conv2d_37': <keras.layers.convolutional.Conv2D at 0x21c8b8cc240>,\n",
       " 'conv2d_38': <keras.layers.convolutional.Conv2D at 0x21c8ba02828>,\n",
       " 'conv2d_39': <keras.layers.convolutional.Conv2D at 0x21c8ba65c18>,\n",
       " 'conv2d_4': <keras.layers.convolutional.Conv2D at 0x21c89207e80>,\n",
       " 'conv2d_40': <keras.layers.convolutional.Conv2D at 0x21c8bb26a58>,\n",
       " 'conv2d_41': <keras.layers.convolutional.Conv2D at 0x21c8bc24f60>,\n",
       " 'conv2d_42': <keras.layers.convolutional.Conv2D at 0x21c8bcaf3c8>,\n",
       " 'conv2d_43': <keras.layers.convolutional.Conv2D at 0x21c8bda1fd0>,\n",
       " 'conv2d_44': <keras.layers.convolutional.Conv2D at 0x21c8bdd0dd8>,\n",
       " 'conv2d_45': <keras.layers.convolutional.Conv2D at 0x21c8bf05828>,\n",
       " 'conv2d_46': <keras.layers.convolutional.Conv2D at 0x21c8bfc7fd0>,\n",
       " 'conv2d_47': <keras.layers.convolutional.Conv2D at 0x21c8bff8e48>,\n",
       " 'conv2d_48': <keras.layers.convolutional.Conv2D at 0x21c8c12d860>,\n",
       " 'conv2d_49': <keras.layers.convolutional.Conv2D at 0x21c8c18ff98>,\n",
       " 'conv2d_5': <keras.layers.convolutional.Conv2D at 0x21c8929ec50>,\n",
       " 'conv2d_50': <keras.layers.convolutional.Conv2D at 0x21c8c24fba8>,\n",
       " 'conv2d_51': <keras.layers.convolutional.Conv2D at 0x21c8c34fda0>,\n",
       " 'conv2d_52': <keras.layers.convolutional.Conv2D at 0x21c8c496b70>,\n",
       " 'conv2d_53': <keras.layers.convolutional.Conv2D at 0x21c8c4cdf60>,\n",
       " 'conv2d_54': <keras.layers.convolutional.Conv2D at 0x21c8c4ff9e8>,\n",
       " 'conv2d_55': <keras.layers.convolutional.Conv2D at 0x21c8c631b00>,\n",
       " 'conv2d_56': <keras.layers.convolutional.Conv2D at 0x21c8c6edfd0>,\n",
       " 'conv2d_57': <keras.layers.convolutional.Conv2D at 0x21c8c774e80>,\n",
       " 'conv2d_58': <keras.layers.convolutional.Conv2D at 0x21c8c856b00>,\n",
       " 'conv2d_59': <keras.layers.convolutional.Conv2D at 0x21c8c915588>,\n",
       " 'conv2d_6': <keras.layers.convolutional.Conv2D at 0x21c87e183c8>,\n",
       " 'conv2d_60': <keras.layers.convolutional.Conv2D at 0x21c8c9e42b0>,\n",
       " 'conv2d_61': <keras.layers.convolutional.Conv2D at 0x21c8ca7ae48>,\n",
       " 'conv2d_62': <keras.layers.convolutional.Conv2D at 0x21c8cbc25c0>,\n",
       " 'conv2d_63': <keras.layers.convolutional.Conv2D at 0x21c8cbf7a58>,\n",
       " 'conv2d_64': <keras.layers.convolutional.Conv2D at 0x21c8cc29908>,\n",
       " 'conv2d_65': <keras.layers.convolutional.Conv2D at 0x21c8dd2cf28>,\n",
       " 'conv2d_66': <keras.layers.convolutional.Conv2D at 0x21c8dd5d2b0>,\n",
       " 'conv2d_67': <keras.layers.convolutional.Conv2D at 0x21c8de1eda0>,\n",
       " 'conv2d_68': <keras.layers.convolutional.Conv2D at 0x21c8df51f60>,\n",
       " 'conv2d_69': <keras.layers.convolutional.Conv2D at 0x21c8e00c5f8>,\n",
       " 'conv2d_7': <keras.layers.convolutional.Conv2D at 0x21c8944ec18>,\n",
       " 'conv2d_70': <keras.layers.convolutional.Conv2D at 0x21c8e0e1eb8>,\n",
       " 'conv2d_71': <keras.layers.convolutional.Conv2D at 0x21c8e178eb8>,\n",
       " 'conv2d_72': <keras.layers.convolutional.Conv2D at 0x21c8e20b748>,\n",
       " 'conv2d_73': <keras.layers.convolutional.Conv2D at 0x21c8e2f15f8>,\n",
       " 'conv2d_74': <keras.layers.convolutional.Conv2D at 0x21c8e323be0>,\n",
       " 'conv2d_75': <keras.layers.convolutional.Conv2D at 0x21c8e456f60>,\n",
       " 'conv2d_76': <keras.layers.convolutional.Conv2D at 0x21c8e5175f8>,\n",
       " 'conv2d_77': <keras.layers.convolutional.Conv2D at 0x21c8e5e60b8>,\n",
       " 'conv2d_78': <keras.layers.convolutional.Conv2D at 0x21c8e67cf28>,\n",
       " 'conv2d_79': <keras.layers.convolutional.Conv2D at 0x21c8e7c4f28>,\n",
       " 'conv2d_8': <keras.layers.convolutional.Conv2D at 0x21c8950b8d0>,\n",
       " 'conv2d_80': <keras.layers.convolutional.Conv2D at 0x21c8e7f7588>,\n",
       " 'conv2d_81': <keras.layers.convolutional.Conv2D at 0x21c8e85fe10>,\n",
       " 'conv2d_82': <keras.layers.convolutional.Conv2D at 0x21c8e8e88d0>,\n",
       " 'conv2d_83': <keras.layers.convolutional.Conv2D at 0x21c8ea212e8>,\n",
       " 'conv2d_84': <keras.layers.convolutional.Conv2D at 0x21c8ea53be0>,\n",
       " 'conv2d_85': <keras.layers.convolutional.Conv2D at 0x21c8ec13860>,\n",
       " 'conv2d_86': <keras.layers.convolutional.Conv2D at 0x21c8ec47eb8>,\n",
       " 'conv2d_87': <keras.layers.convolutional.Conv2D at 0x21c8ed89ba8>,\n",
       " 'conv2d_88': <keras.layers.convolutional.Conv2D at 0x21c8ed36cf8>,\n",
       " 'conv2d_89': <keras.layers.convolutional.Conv2D at 0x21c8ee6df98>,\n",
       " 'conv2d_9': <keras.layers.convolutional.Conv2D at 0x21c894fbbe0>,\n",
       " 'conv2d_90': <keras.layers.convolutional.Conv2D at 0x21c8eece390>,\n",
       " 'conv2d_91': <keras.layers.convolutional.Conv2D at 0x21c8ef5e9e8>,\n",
       " 'conv2d_92': <keras.layers.convolutional.Conv2D at 0x21c8f0d6d68>,\n",
       " 'conv2d_93': <keras.layers.convolutional.Conv2D at 0x21c8f14e7f0>,\n",
       " 'conv2d_94': <keras.layers.convolutional.Conv2D at 0x21c8f17ee80>,\n",
       " 'input_1': <keras.engine.input_layer.InputLayer at 0x21c87f8dd30>,\n",
       " 'max_pooling2d_1': <keras.layers.pooling.MaxPooling2D at 0x21c8919ff28>,\n",
       " 'max_pooling2d_2': <keras.layers.pooling.MaxPooling2D at 0x21c8935b748>,\n",
       " 'max_pooling2d_3': <keras.layers.pooling.MaxPooling2D at 0x21c8a52eb00>,\n",
       " 'max_pooling2d_4': <keras.layers.pooling.MaxPooling2D at 0x21c8e57deb8>,\n",
       " 'mixed0': <keras.layers.merge.Concatenate at 0x21c89851fd0>,\n",
       " 'mixed1': <keras.layers.merge.Concatenate at 0x21c89d50f28>,\n",
       " 'mixed10': <keras.layers.merge.Concatenate at 0x21c82549518>,\n",
       " 'mixed2': <keras.layers.merge.Concatenate at 0x21c8a292be0>,\n",
       " 'mixed3': <keras.layers.merge.Concatenate at 0x21c8a4f6c88>,\n",
       " 'mixed4': <keras.layers.merge.Concatenate at 0x21c8bc68cc0>,\n",
       " 'mixed5': <keras.layers.merge.Concatenate at 0x21c8c394c88>,\n",
       " 'mixed6': <keras.layers.merge.Concatenate at 0x21c8cabff98>,\n",
       " 'mixed7': <keras.layers.merge.Concatenate at 0x21c8e178f98>,\n",
       " 'mixed8': <keras.layers.merge.Concatenate at 0x21c8e5e6eb8>,\n",
       " 'mixed9': <keras.layers.merge.Concatenate at 0x21c8ecd0cc0>,\n",
       " 'mixed9_0': <keras.layers.merge.Concatenate at 0x21c8e85fcc0>,\n",
       " 'mixed9_1': <keras.layers.merge.Concatenate at 0x21c8ef708d0>}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
    "layer_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=float32_ref>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = K.variable(0.)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable += will be deprecated. Use variable.assign_add if you want assignment to the variable value or 'x = x + y' if you want a new python Tensor object.\n"
     ]
    }
   ],
   "source": [
    "# keras.backend.prod(x, axis=None, keepdims=False)\n",
    "# 在某一指定轴，计算张量中的值的乘积。\n",
    "for layer_name in layer_contributions:\n",
    "    coeff = layer_contributions[layer_name]\n",
    "    activation = layer_dict[layer_name].output\n",
    "    \n",
    "    scaling = K.prod(K.cast(K.shape(activation), 'float32'))\n",
    "    loss += coeff * K.sum(K.square(activation[:, 2: -2, 2: -2, :])) / scaling\n",
    "#WARNING:tensorflow:Variable += will be deprecated. \n",
    "#Use variable.assign_add if you want assignment to the variable value or 'x = x + y' if you want a new python Tensor object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'activation_94/Relu:0' shape=(?, ?, ?, 192) dtype=float32>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(None), Dimension(None), Dimension(192)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'strided_slice_4:0' shape=(?, ?, ?, 192) dtype=float32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation[:, 2: -2, 2: -2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(None), Dimension(None), Dimension(192)])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation[:, 2: -2, 2: -2, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.77147638, 0.80351985, 0.99897626, ..., 0.74351736,\n",
       "          0.4552565 , 0.63064187],\n",
       "         [0.53415717, 0.28003292, 0.06011286, ..., 0.31460366,\n",
       "          0.889959  , 0.33317639],\n",
       "         [0.98395711, 0.42135504, 0.03193452, ..., 0.24829896,\n",
       "          0.17837492, 0.44345865],\n",
       "         ...,\n",
       "         [0.13668955, 0.66528979, 0.73227538, ..., 0.67865716,\n",
       "          0.86261658, 0.06498642],\n",
       "         [0.46804779, 0.82533401, 0.10023764, ..., 0.36688403,\n",
       "          0.11589357, 0.70151632],\n",
       "         [0.35673142, 0.57745301, 0.98621367, ..., 0.49021446,\n",
       "          0.44692248, 0.25979811]],\n",
       "\n",
       "        [[0.66853825, 0.09302805, 0.47300475, ..., 0.16254072,\n",
       "          0.09493468, 0.63980146],\n",
       "         [0.77329842, 0.92800512, 0.36690145, ..., 0.01137691,\n",
       "          0.40871647, 0.14683201],\n",
       "         [0.30637711, 0.65144921, 0.14753353, ..., 0.00817554,\n",
       "          0.99324109, 0.22662307],\n",
       "         ...,\n",
       "         [0.78962846, 0.34463083, 0.6308551 , ..., 0.97801888,\n",
       "          0.91225285, 0.49455555],\n",
       "         [0.38929211, 0.42672501, 0.37667278, ..., 0.20467665,\n",
       "          0.64062941, 0.34892889],\n",
       "         [0.61520939, 0.13882989, 0.57965109, ..., 0.33364177,\n",
       "          0.5688712 , 0.71601733]],\n",
       "\n",
       "        [[0.95280053, 0.69238823, 0.2502781 , ..., 0.92267615,\n",
       "          0.86305179, 0.62019213],\n",
       "         [0.6136093 , 0.68174612, 0.9159571 , ..., 0.23387655,\n",
       "          0.95456135, 0.57603465],\n",
       "         [0.47222614, 0.92466923, 0.55328833, ..., 0.39402066,\n",
       "          0.48510808, 0.95321862],\n",
       "         ...,\n",
       "         [0.80818041, 0.86163525, 0.59617024, ..., 0.82923934,\n",
       "          0.53124334, 0.25844821],\n",
       "         [0.89710849, 0.04567784, 0.35786428, ..., 0.37491047,\n",
       "          0.65811074, 0.05442574],\n",
       "         [0.97297481, 0.09872184, 0.17344537, ..., 0.42406912,\n",
       "          0.60992493, 0.80871418]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.97612124, 0.08933119, 0.75150998, ..., 0.61695992,\n",
       "          0.16314347, 0.78927612],\n",
       "         [0.69908479, 0.09197557, 0.53462392, ..., 0.84367302,\n",
       "          0.44466018, 0.34992661],\n",
       "         [0.78314666, 0.26302321, 0.72098033, ..., 0.28304434,\n",
       "          0.01590302, 0.6788603 ],\n",
       "         ...,\n",
       "         [0.95932572, 0.01362284, 0.12435879, ..., 0.70738939,\n",
       "          0.42700194, 0.37555017],\n",
       "         [0.23550662, 0.89642269, 0.36526728, ..., 0.23259758,\n",
       "          0.96535196, 0.49642478],\n",
       "         [0.54988069, 0.18410825, 0.98778218, ..., 0.76860449,\n",
       "          0.40579245, 0.49012021]],\n",
       "\n",
       "        [[0.39550643, 0.27040574, 0.62599278, ..., 0.62190798,\n",
       "          0.77372365, 0.6825559 ],\n",
       "         [0.63871287, 0.00468139, 0.53697606, ..., 0.35095424,\n",
       "          0.34862964, 0.90996137],\n",
       "         [0.88178404, 0.28956454, 0.80231119, ..., 0.86944629,\n",
       "          0.83693677, 0.42535265],\n",
       "         ...,\n",
       "         [0.64262256, 0.68925775, 0.66778964, ..., 0.41864483,\n",
       "          0.19984395, 0.10036153],\n",
       "         [0.49710834, 0.40770075, 0.18912755, ..., 0.56106578,\n",
       "          0.95176665, 0.87907244],\n",
       "         [0.3589402 , 0.66049253, 0.15694462, ..., 0.83099095,\n",
       "          0.02582338, 0.78403234]],\n",
       "\n",
       "        [[0.80188425, 0.16109282, 0.99349184, ..., 0.95552578,\n",
       "          0.00648644, 0.9796073 ],\n",
       "         [0.0232    , 0.80622878, 0.10591333, ..., 0.26073473,\n",
       "          0.84757435, 0.81266086],\n",
       "         [0.97335492, 0.66554772, 0.76225002, ..., 0.03084711,\n",
       "          0.30623206, 0.71124462],\n",
       "         ...,\n",
       "         [0.4629728 , 0.02668791, 0.20655384, ..., 0.28416698,\n",
       "          0.79784357, 0.86738048],\n",
       "         [0.00767471, 0.50174601, 0.08666081, ..., 0.07488696,\n",
       "          0.46247182, 0.87773469],\n",
       "         [0.21998797, 0.65873073, 0.00838178, ..., 0.13709846,\n",
       "          0.82364273, 0.80245979]]],\n",
       "\n",
       "\n",
       "       [[[0.8200558 , 0.74525891, 0.11114224, ..., 0.94899112,\n",
       "          0.49614375, 0.70429572],\n",
       "         [0.66461345, 0.25594302, 0.2971515 , ..., 0.3680222 ,\n",
       "          0.90883146, 0.66274352],\n",
       "         [0.14306604, 0.64114455, 0.40029429, ..., 0.60589138,\n",
       "          0.86654281, 0.07634843],\n",
       "         ...,\n",
       "         [0.17432467, 0.62558522, 0.14324335, ..., 0.49571765,\n",
       "          0.82152734, 0.57827181],\n",
       "         [0.70758827, 0.56062547, 0.85605515, ..., 0.64740791,\n",
       "          0.29116919, 0.91243156],\n",
       "         [0.7503246 , 0.39530924, 0.42030273, ..., 0.10825752,\n",
       "          0.96118333, 0.08010378]],\n",
       "\n",
       "        [[0.19770729, 0.45905218, 0.18591866, ..., 0.19420008,\n",
       "          0.97979978, 0.6444981 ],\n",
       "         [0.60406913, 0.49028504, 0.06195502, ..., 0.24433829,\n",
       "          0.14832162, 0.59212343],\n",
       "         [0.17564378, 0.06984005, 0.53774024, ..., 0.04830937,\n",
       "          0.75020097, 0.43389536],\n",
       "         ...,\n",
       "         [0.64671513, 0.50205358, 0.97973265, ..., 0.88577951,\n",
       "          0.15912649, 0.69983631],\n",
       "         [0.91168387, 0.64260246, 0.17058141, ..., 0.69660159,\n",
       "          0.06741726, 0.2429484 ],\n",
       "         [0.36183545, 0.75814804, 0.37860969, ..., 0.78553628,\n",
       "          0.07431664, 0.81486941]],\n",
       "\n",
       "        [[0.39945973, 0.56008109, 0.05883549, ..., 0.24964691,\n",
       "          0.89302413, 0.30406958],\n",
       "         [0.63683495, 0.00590774, 0.50110621, ..., 0.42364686,\n",
       "          0.01628444, 0.15298638],\n",
       "         [0.23873921, 0.46911661, 0.39286624, ..., 0.20880086,\n",
       "          0.49051823, 0.6377753 ],\n",
       "         ...,\n",
       "         [0.79586248, 0.88204288, 0.87119769, ..., 0.59216126,\n",
       "          0.18127431, 0.36591658],\n",
       "         [0.96911395, 0.28743424, 0.31807624, ..., 0.83254348,\n",
       "          0.73262913, 0.73885189],\n",
       "         [0.98485703, 0.93247815, 0.64200897, ..., 0.77292626,\n",
       "          0.62590631, 0.48336859]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.23779321, 0.38919104, 0.05319954, ..., 0.53161778,\n",
       "          0.22429029, 0.27090903],\n",
       "         [0.68472771, 0.75621955, 0.54978773, ..., 0.56392736,\n",
       "          0.95231789, 0.31828633],\n",
       "         [0.95205297, 0.12223333, 0.39344355, ..., 0.25788957,\n",
       "          0.6527417 , 0.98534892],\n",
       "         ...,\n",
       "         [0.15931457, 0.65094738, 0.45455549, ..., 0.84012162,\n",
       "          0.54048629, 0.7192396 ],\n",
       "         [0.39717212, 0.07171229, 0.95722708, ..., 0.51797773,\n",
       "          0.16682334, 0.62102057],\n",
       "         [0.2554032 , 0.94962724, 0.16234647, ..., 0.49508093,\n",
       "          0.80236159, 0.01460468]],\n",
       "\n",
       "        [[0.50006359, 0.24679765, 0.09534027, ..., 0.18537213,\n",
       "          0.95892523, 0.53051231],\n",
       "         [0.69839823, 0.68874898, 0.69498416, ..., 0.36416991,\n",
       "          0.84622362, 0.40820194],\n",
       "         [0.02354858, 0.82441094, 0.05868593, ..., 0.8240758 ,\n",
       "          0.47418629, 0.14629746],\n",
       "         ...,\n",
       "         [0.42111348, 0.49044235, 0.16599178, ..., 0.66332675,\n",
       "          0.41072637, 0.8577075 ],\n",
       "         [0.11551281, 0.05344777, 0.39592214, ..., 0.58725131,\n",
       "          0.86148422, 0.47223753],\n",
       "         [0.45397874, 0.79603755, 0.01526342, ..., 0.11770859,\n",
       "          0.39897359, 0.43181268]],\n",
       "\n",
       "        [[0.72336049, 0.21411931, 0.67273829, ..., 0.09003318,\n",
       "          0.65812323, 0.57320493],\n",
       "         [0.9635827 , 0.11854572, 0.15376075, ..., 0.18081128,\n",
       "          0.19413376, 0.5363188 ],\n",
       "         [0.93513216, 0.55436988, 0.62446611, ..., 0.94917968,\n",
       "          0.62730453, 0.56655258],\n",
       "         ...,\n",
       "         [0.82200675, 0.2419657 , 0.91957674, ..., 0.17750115,\n",
       "          0.47479657, 0.89980563],\n",
       "         [0.36544583, 0.45988588, 0.34283078, ..., 0.4984991 ,\n",
       "          0.73779823, 0.5937302 ],\n",
       "         [0.25456841, 0.32134807, 0.53103842, ..., 0.91876584,\n",
       "          0.15087674, 0.26412916]]],\n",
       "\n",
       "\n",
       "       [[[0.41142143, 0.65085974, 0.14042693, ..., 0.76754513,\n",
       "          0.91345105, 0.64930206],\n",
       "         [0.71950334, 0.48035936, 0.49810455, ..., 0.23788829,\n",
       "          0.07468554, 0.95919681],\n",
       "         [0.11747184, 0.45511317, 0.58092353, ..., 0.79057607,\n",
       "          0.22510682, 0.47933174],\n",
       "         ...,\n",
       "         [0.90899022, 0.78487629, 0.48628826, ..., 0.36311624,\n",
       "          0.11243785, 0.98135647],\n",
       "         [0.13742289, 0.68523793, 0.6908224 , ..., 0.14675924,\n",
       "          0.70235653, 0.51582033],\n",
       "         [0.47208615, 0.37569307, 0.14669431, ..., 0.78214918,\n",
       "          0.17992871, 0.11184998]],\n",
       "\n",
       "        [[0.72674224, 0.95812857, 0.64852624, ..., 0.13561214,\n",
       "          0.59444249, 0.57752349],\n",
       "         [0.84199025, 0.79209212, 0.69076052, ..., 0.80514431,\n",
       "          0.05888487, 0.88967765],\n",
       "         [0.89574498, 0.76508021, 0.5469454 , ..., 0.19193325,\n",
       "          0.05472391, 0.06834743],\n",
       "         ...,\n",
       "         [0.16557591, 0.58683924, 0.76809131, ..., 0.3960904 ,\n",
       "          0.76868779, 0.02596094],\n",
       "         [0.86086722, 0.37453815, 0.21603373, ..., 0.39985707,\n",
       "          0.97312086, 0.66749641],\n",
       "         [0.83362566, 0.61064878, 0.82610854, ..., 0.2849322 ,\n",
       "          0.21337659, 0.20129353]],\n",
       "\n",
       "        [[0.92001788, 0.31565894, 0.66839135, ..., 0.03087129,\n",
       "          0.26054316, 0.30357678],\n",
       "         [0.16722038, 0.13515465, 0.75234223, ..., 0.32337763,\n",
       "          0.3445111 , 0.02426703],\n",
       "         [0.88354698, 0.94485484, 0.87894792, ..., 0.5437174 ,\n",
       "          0.5225799 , 0.49315916],\n",
       "         ...,\n",
       "         [0.49544159, 0.89775322, 0.77133498, ..., 0.7457843 ,\n",
       "          0.99760905, 0.24269769],\n",
       "         [0.92133879, 0.92078528, 0.41013483, ..., 0.15205726,\n",
       "          0.04920357, 0.79123053],\n",
       "         [0.66973994, 0.69462014, 0.37154397, ..., 0.61407664,\n",
       "          0.23569801, 0.59732266]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.20157284, 0.42256952, 0.52056356, ..., 0.4029274 ,\n",
       "          0.37208237, 0.4630843 ],\n",
       "         [0.15021697, 0.30752203, 0.75837216, ..., 0.20417961,\n",
       "          0.47973727, 0.68165527],\n",
       "         [0.86495159, 0.93519903, 0.19187267, ..., 0.44966564,\n",
       "          0.12295992, 0.88629935],\n",
       "         ...,\n",
       "         [0.82167451, 0.37691183, 0.0847953 , ..., 0.29508504,\n",
       "          0.08449393, 0.70859099],\n",
       "         [0.05101175, 0.79508837, 0.01443699, ..., 0.61077919,\n",
       "          0.3963774 , 0.22477516],\n",
       "         [0.93783705, 0.16031254, 0.60204515, ..., 0.73714212,\n",
       "          0.01338325, 0.91696042]],\n",
       "\n",
       "        [[0.63015244, 0.85232781, 0.37545911, ..., 0.6000618 ,\n",
       "          0.0027745 , 0.86999883],\n",
       "         [0.19094578, 0.4734714 , 0.42644948, ..., 0.56227692,\n",
       "          0.60107731, 0.02468934],\n",
       "         [0.43200447, 0.58292329, 0.72328789, ..., 0.04506126,\n",
       "          0.73813668, 0.5744447 ],\n",
       "         ...,\n",
       "         [0.79256979, 0.36289281, 0.39000718, ..., 0.87751322,\n",
       "          0.92043518, 0.27360591],\n",
       "         [0.84954125, 0.71841092, 0.80642389, ..., 0.75893467,\n",
       "          0.96087525, 0.02094959],\n",
       "         [0.442292  , 0.32716826, 0.63586106, ..., 0.82885112,\n",
       "          0.55143793, 0.71455312]],\n",
       "\n",
       "        [[0.24837209, 0.99414691, 0.30249754, ..., 0.08304566,\n",
       "          0.12652243, 0.67796515],\n",
       "         [0.97274069, 0.56391515, 0.12478822, ..., 0.95186888,\n",
       "          0.98817313, 0.1787563 ],\n",
       "         [0.01004894, 0.2753956 , 0.19040469, ..., 0.81202585,\n",
       "          0.8198091 , 0.86495125],\n",
       "         ...,\n",
       "         [0.93466511, 0.85832251, 0.21899056, ..., 0.53769875,\n",
       "          0.52703662, 0.34608683],\n",
       "         [0.18621567, 0.81780824, 0.41407165, ..., 0.10174428,\n",
       "          0.66251223, 0.64751079],\n",
       "         [0.47672327, 0.28940979, 0.01144887, ..., 0.6244212 ,\n",
       "          0.36504197, 0.27283045]]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "temp = np.random.random((3, 100, 100, 192))\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[7.73298421e-01, 9.28005122e-01, 3.66901454e-01, ...,\n",
       "          1.13769145e-02, 4.08716475e-01, 1.46832007e-01],\n",
       "         [3.06377112e-01, 6.51449212e-01, 1.47533530e-01, ...,\n",
       "          8.17553560e-03, 9.93241087e-01, 2.26623074e-01],\n",
       "         [3.09273536e-01, 8.44162845e-01, 6.94256233e-01, ...,\n",
       "          7.12814529e-01, 2.27645203e-01, 6.49342385e-01],\n",
       "         ...,\n",
       "         [6.67396716e-01, 3.22895169e-01, 9.57252412e-01, ...,\n",
       "          2.99156459e-01, 7.68465224e-01, 1.97233601e-01],\n",
       "         [7.89628460e-01, 3.44630826e-01, 6.30855099e-01, ...,\n",
       "          9.78018882e-01, 9.12252852e-01, 4.94555555e-01],\n",
       "         [3.89292111e-01, 4.26725012e-01, 3.76672783e-01, ...,\n",
       "          2.04676649e-01, 6.40629410e-01, 3.48928895e-01]],\n",
       "\n",
       "        [[6.13609296e-01, 6.81746123e-01, 9.15957097e-01, ...,\n",
       "          2.33876554e-01, 9.54561351e-01, 5.76034654e-01],\n",
       "         [4.72226144e-01, 9.24669233e-01, 5.53288327e-01, ...,\n",
       "          3.94020661e-01, 4.85108082e-01, 9.53218623e-01],\n",
       "         [4.49065060e-01, 2.43785568e-01, 9.66763954e-01, ...,\n",
       "          9.52204048e-01, 5.67391011e-01, 4.13613368e-01],\n",
       "         ...,\n",
       "         [4.35105598e-01, 8.95612969e-01, 2.65278410e-01, ...,\n",
       "          3.75152202e-01, 4.16486737e-01, 8.17998361e-02],\n",
       "         [8.08180409e-01, 8.61635246e-01, 5.96170236e-01, ...,\n",
       "          8.29239343e-01, 5.31243337e-01, 2.58448213e-01],\n",
       "         [8.97108489e-01, 4.56778433e-02, 3.57864284e-01, ...,\n",
       "          3.74910471e-01, 6.58110739e-01, 5.44257398e-02]],\n",
       "\n",
       "        [[3.82436135e-01, 6.84097495e-01, 3.26301374e-01, ...,\n",
       "          2.15983710e-01, 2.84112391e-01, 4.42535620e-01],\n",
       "         [8.07689282e-01, 6.65195165e-01, 6.42230528e-01, ...,\n",
       "          3.58543017e-01, 8.89252341e-01, 1.71233403e-01],\n",
       "         [1.00959572e-01, 1.33639480e-01, 1.30222370e-01, ...,\n",
       "          9.73937975e-01, 8.06770210e-01, 3.50900446e-01],\n",
       "         ...,\n",
       "         [5.87571660e-01, 5.12624223e-01, 9.09046876e-01, ...,\n",
       "          2.13814951e-01, 1.05792765e-02, 4.55223974e-02],\n",
       "         [6.02888017e-01, 3.11469893e-01, 4.03806820e-01, ...,\n",
       "          5.31628175e-01, 4.24320285e-01, 5.65098308e-01],\n",
       "         [1.23560801e-01, 3.02485977e-02, 7.05879129e-01, ...,\n",
       "          6.24899638e-01, 7.13516542e-01, 9.73602687e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[8.83130242e-01, 2.33910474e-01, 6.82140002e-01, ...,\n",
       "          5.59459241e-01, 3.52452676e-01, 6.34221600e-02],\n",
       "         [1.94119124e-01, 2.58914293e-01, 2.19818571e-02, ...,\n",
       "          3.23441465e-01, 9.71495525e-01, 4.44339438e-01],\n",
       "         [7.14270152e-01, 6.13273302e-01, 7.26454833e-01, ...,\n",
       "          5.16313308e-01, 3.28149042e-01, 5.13216347e-01],\n",
       "         ...,\n",
       "         [4.98826125e-02, 7.96595876e-01, 2.99825982e-01, ...,\n",
       "          7.98406969e-01, 7.04707657e-01, 7.79012716e-01],\n",
       "         [2.60533862e-01, 3.57057264e-01, 8.82642944e-01, ...,\n",
       "          2.16439693e-01, 5.28997906e-01, 4.38369142e-01],\n",
       "         [1.78135521e-01, 8.88901314e-01, 7.23008788e-01, ...,\n",
       "          7.84854104e-01, 6.29390506e-01, 6.21127603e-02]],\n",
       "\n",
       "        [[6.99084793e-01, 9.19755700e-02, 5.34623923e-01, ...,\n",
       "          8.43673016e-01, 4.44660179e-01, 3.49926609e-01],\n",
       "         [7.83146662e-01, 2.63023207e-01, 7.20980330e-01, ...,\n",
       "          2.83044337e-01, 1.59030225e-02, 6.78860299e-01],\n",
       "         [3.99681133e-01, 2.93889448e-01, 6.38824287e-01, ...,\n",
       "          4.31383916e-02, 8.26043967e-01, 7.62690852e-01],\n",
       "         ...,\n",
       "         [9.93210374e-01, 1.92567840e-01, 5.93538792e-01, ...,\n",
       "          4.59578244e-01, 3.19497721e-01, 2.20207891e-01],\n",
       "         [9.59325719e-01, 1.36228449e-02, 1.24358794e-01, ...,\n",
       "          7.07389391e-01, 4.27001937e-01, 3.75550173e-01],\n",
       "         [2.35506622e-01, 8.96422688e-01, 3.65267283e-01, ...,\n",
       "          2.32597582e-01, 9.65351959e-01, 4.96424780e-01]],\n",
       "\n",
       "        [[6.38712873e-01, 4.68138789e-03, 5.36976064e-01, ...,\n",
       "          3.50954242e-01, 3.48629640e-01, 9.09961370e-01],\n",
       "         [8.81784036e-01, 2.89564535e-01, 8.02311193e-01, ...,\n",
       "          8.69446286e-01, 8.36936767e-01, 4.25352647e-01],\n",
       "         [8.73589802e-01, 7.73600112e-01, 2.68797947e-01, ...,\n",
       "          3.01549895e-01, 5.62659512e-01, 6.24114574e-02],\n",
       "         ...,\n",
       "         [5.79876646e-01, 2.40311624e-01, 4.75392685e-01, ...,\n",
       "          8.21947331e-01, 3.04179445e-01, 2.19771422e-01],\n",
       "         [6.42622555e-01, 6.89257751e-01, 6.67789636e-01, ...,\n",
       "          4.18644826e-01, 1.99843954e-01, 1.00361528e-01],\n",
       "         [4.97108342e-01, 4.07700747e-01, 1.89127545e-01, ...,\n",
       "          5.61065779e-01, 9.51766646e-01, 8.79072438e-01]]],\n",
       "\n",
       "\n",
       "       [[[6.04069125e-01, 4.90285043e-01, 6.19550228e-02, ...,\n",
       "          2.44338287e-01, 1.48321619e-01, 5.92123429e-01],\n",
       "         [1.75643781e-01, 6.98400459e-02, 5.37740245e-01, ...,\n",
       "          4.83093666e-02, 7.50200971e-01, 4.33895356e-01],\n",
       "         [7.55398098e-01, 9.59000663e-01, 1.08369104e-02, ...,\n",
       "          5.91172533e-01, 4.49225245e-01, 2.07778938e-01],\n",
       "         ...,\n",
       "         [3.78838545e-01, 2.93774937e-01, 9.91617980e-01, ...,\n",
       "          5.03457744e-01, 4.44141482e-01, 8.25599430e-01],\n",
       "         [6.46715127e-01, 5.02053585e-01, 9.79732653e-01, ...,\n",
       "          8.85779515e-01, 1.59126490e-01, 6.99836315e-01],\n",
       "         [9.11683868e-01, 6.42602462e-01, 1.70581410e-01, ...,\n",
       "          6.96601595e-01, 6.74172558e-02, 2.42948395e-01]],\n",
       "\n",
       "        [[6.36834947e-01, 5.90773816e-03, 5.01106212e-01, ...,\n",
       "          4.23646856e-01, 1.62844428e-02, 1.52986378e-01],\n",
       "         [2.38739211e-01, 4.69116611e-01, 3.92866235e-01, ...,\n",
       "          2.08800857e-01, 4.90518233e-01, 6.37775302e-01],\n",
       "         [1.87015041e-01, 5.50103380e-01, 5.39704563e-01, ...,\n",
       "          7.94177224e-01, 8.65463884e-01, 8.54235750e-01],\n",
       "         ...,\n",
       "         [8.21795998e-01, 9.15161108e-01, 8.40430867e-01, ...,\n",
       "          4.56620215e-01, 2.63923277e-01, 4.91134193e-01],\n",
       "         [7.95862478e-01, 8.82042881e-01, 8.71197687e-01, ...,\n",
       "          5.92161262e-01, 1.81274311e-01, 3.65916583e-01],\n",
       "         [9.69113945e-01, 2.87434237e-01, 3.18076238e-01, ...,\n",
       "          8.32543484e-01, 7.32629131e-01, 7.38851890e-01]],\n",
       "\n",
       "        [[2.72709111e-02, 7.12889763e-01, 3.75703939e-02, ...,\n",
       "          5.78277861e-01, 8.76273803e-01, 7.93144906e-01],\n",
       "         [8.05135309e-01, 8.36556085e-01, 3.11859446e-01, ...,\n",
       "          1.61329901e-01, 6.96440853e-02, 2.17397960e-01],\n",
       "         [4.02205353e-01, 1.39347060e-01, 5.34091426e-01, ...,\n",
       "          4.47231367e-01, 6.05421694e-01, 5.44616693e-01],\n",
       "         ...,\n",
       "         [8.48200239e-01, 4.46852298e-01, 3.37900187e-01, ...,\n",
       "          1.44539225e-01, 9.54278666e-01, 3.60083057e-01],\n",
       "         [3.24182920e-01, 7.62368479e-01, 1.43348446e-01, ...,\n",
       "          4.18475496e-01, 5.63870086e-03, 7.47643074e-01],\n",
       "         [5.51546046e-01, 5.78765794e-01, 6.46484746e-01, ...,\n",
       "          5.63382150e-01, 7.18773377e-01, 3.78657604e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[4.45168992e-01, 2.03825806e-01, 3.22851570e-01, ...,\n",
       "          2.51936943e-01, 3.32599681e-01, 2.15013870e-01],\n",
       "         [9.79487128e-01, 8.16603482e-01, 2.94678547e-01, ...,\n",
       "          9.41757301e-01, 9.93229606e-01, 9.60992514e-02],\n",
       "         [9.72910194e-01, 2.32542559e-01, 4.60055054e-01, ...,\n",
       "          4.41804670e-04, 7.90870786e-01, 8.20335925e-01],\n",
       "         ...,\n",
       "         [2.61270878e-01, 8.04003095e-01, 3.78942131e-01, ...,\n",
       "          2.12224585e-01, 3.73607486e-01, 7.33608396e-01],\n",
       "         [7.53362209e-01, 1.66465022e-01, 5.14504943e-01, ...,\n",
       "          4.15911310e-01, 9.09381903e-01, 3.40948967e-01],\n",
       "         [8.07620947e-01, 1.50149271e-01, 4.01813814e-01, ...,\n",
       "          7.23700363e-01, 1.20385051e-01, 6.59593516e-01]],\n",
       "\n",
       "        [[6.84727711e-01, 7.56219553e-01, 5.49787727e-01, ...,\n",
       "          5.63927358e-01, 9.52317886e-01, 3.18286327e-01],\n",
       "         [9.52052969e-01, 1.22233329e-01, 3.93443548e-01, ...,\n",
       "          2.57889571e-01, 6.52741696e-01, 9.85348925e-01],\n",
       "         [2.97137312e-01, 8.89788459e-01, 9.95443911e-01, ...,\n",
       "          6.82861270e-01, 7.08187547e-01, 6.58181865e-01],\n",
       "         ...,\n",
       "         [3.39698660e-01, 2.57430389e-01, 7.46407330e-01, ...,\n",
       "          3.61468065e-01, 3.06949450e-01, 2.13502430e-02],\n",
       "         [1.59314566e-01, 6.50947379e-01, 4.54555490e-01, ...,\n",
       "          8.40121615e-01, 5.40486287e-01, 7.19239599e-01],\n",
       "         [3.97172123e-01, 7.17122869e-02, 9.57227079e-01, ...,\n",
       "          5.17977733e-01, 1.66823335e-01, 6.21020575e-01]],\n",
       "\n",
       "        [[6.98398228e-01, 6.88748979e-01, 6.94984160e-01, ...,\n",
       "          3.64169908e-01, 8.46223616e-01, 4.08201938e-01],\n",
       "         [2.35485834e-02, 8.24410935e-01, 5.86859267e-02, ...,\n",
       "          8.24075801e-01, 4.74186285e-01, 1.46297461e-01],\n",
       "         [9.70328030e-01, 5.91611434e-01, 3.63502332e-01, ...,\n",
       "          3.67831827e-01, 7.34593965e-01, 4.34251100e-01],\n",
       "         ...,\n",
       "         [6.11012634e-01, 7.59116091e-01, 3.18631869e-01, ...,\n",
       "          4.94586511e-01, 6.12968960e-01, 6.27445248e-01],\n",
       "         [4.21113476e-01, 4.90442345e-01, 1.65991783e-01, ...,\n",
       "          6.63326752e-01, 4.10726368e-01, 8.57707499e-01],\n",
       "         [1.15512812e-01, 5.34477712e-02, 3.95922139e-01, ...,\n",
       "          5.87251313e-01, 8.61484216e-01, 4.72237534e-01]]],\n",
       "\n",
       "\n",
       "       [[[8.41990254e-01, 7.92092124e-01, 6.90760522e-01, ...,\n",
       "          8.05144313e-01, 5.88848736e-02, 8.89677651e-01],\n",
       "         [8.95744981e-01, 7.65080213e-01, 5.46945400e-01, ...,\n",
       "          1.91933248e-01, 5.47239060e-02, 6.83474337e-02],\n",
       "         [6.38842554e-02, 7.57035550e-01, 9.90872619e-01, ...,\n",
       "          7.89371417e-01, 3.74759362e-01, 9.66451888e-01],\n",
       "         ...,\n",
       "         [7.72022868e-01, 2.54079601e-01, 8.98672558e-01, ...,\n",
       "          9.95730563e-01, 4.76256695e-01, 9.73263818e-01],\n",
       "         [1.65575914e-01, 5.86839242e-01, 7.68091307e-01, ...,\n",
       "          3.96090395e-01, 7.68687791e-01, 2.59609444e-02],\n",
       "         [8.60867223e-01, 3.74538147e-01, 2.16033734e-01, ...,\n",
       "          3.99857065e-01, 9.73120859e-01, 6.67496408e-01]],\n",
       "\n",
       "        [[1.67220380e-01, 1.35154655e-01, 7.52342226e-01, ...,\n",
       "          3.23377627e-01, 3.44511097e-01, 2.42670305e-02],\n",
       "         [8.83546984e-01, 9.44854837e-01, 8.78947920e-01, ...,\n",
       "          5.43717400e-01, 5.22579901e-01, 4.93159160e-01],\n",
       "         [7.42646680e-01, 3.42692317e-01, 8.19355661e-01, ...,\n",
       "          2.61731812e-01, 9.40406584e-01, 1.61366377e-02],\n",
       "         ...,\n",
       "         [4.72105563e-01, 2.81300247e-01, 6.25683295e-01, ...,\n",
       "          6.68468820e-03, 8.88158870e-01, 4.05812066e-01],\n",
       "         [4.95441588e-01, 8.97753218e-01, 7.71334984e-01, ...,\n",
       "          7.45784297e-01, 9.97609055e-01, 2.42697687e-01],\n",
       "         [9.21338793e-01, 9.20785284e-01, 4.10134830e-01, ...,\n",
       "          1.52057265e-01, 4.92035740e-02, 7.91230527e-01]],\n",
       "\n",
       "        [[9.26421821e-01, 1.46360119e-01, 6.27696760e-01, ...,\n",
       "          4.73768135e-01, 9.55648473e-01, 3.59148752e-01],\n",
       "         [2.22293781e-01, 8.99827968e-02, 8.26397808e-01, ...,\n",
       "          6.59605099e-01, 3.82550979e-01, 8.80730707e-01],\n",
       "         [8.05083316e-01, 6.91721851e-01, 4.31310510e-01, ...,\n",
       "          3.17284342e-01, 7.60234308e-02, 3.68098921e-01],\n",
       "         ...,\n",
       "         [4.18085761e-01, 5.53553377e-01, 3.58602959e-01, ...,\n",
       "          6.95318837e-01, 9.07305981e-01, 9.11615827e-01],\n",
       "         [6.63494438e-01, 8.33224692e-01, 7.52324825e-02, ...,\n",
       "          9.10380692e-01, 8.45689657e-01, 8.81835532e-01],\n",
       "         [3.19186778e-01, 7.39018048e-01, 3.23485938e-01, ...,\n",
       "          7.59453394e-01, 5.47423743e-01, 1.97733212e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[2.17257277e-01, 4.28176831e-03, 4.39879396e-03, ...,\n",
       "          4.76160078e-02, 2.02753070e-01, 2.43083396e-01],\n",
       "         [3.19074552e-01, 3.30423362e-01, 4.82583693e-01, ...,\n",
       "          7.64772483e-01, 1.04802175e-01, 4.17611275e-01],\n",
       "         [5.07809876e-01, 9.50374774e-01, 3.69304233e-02, ...,\n",
       "          4.25344361e-01, 3.63095106e-01, 6.94857609e-01],\n",
       "         ...,\n",
       "         [1.37276600e-01, 9.62520157e-01, 9.81619218e-01, ...,\n",
       "          2.73638794e-01, 2.99552566e-01, 5.59112660e-01],\n",
       "         [4.12655897e-01, 3.69689920e-01, 4.69379064e-01, ...,\n",
       "          1.64979037e-01, 6.31354460e-01, 1.74491889e-01],\n",
       "         [8.98923502e-01, 2.18681514e-02, 5.99584053e-01, ...,\n",
       "          8.53669112e-01, 3.60966981e-01, 2.02640245e-01]],\n",
       "\n",
       "        [[1.50216967e-01, 3.07522033e-01, 7.58372160e-01, ...,\n",
       "          2.04179607e-01, 4.79737266e-01, 6.81655269e-01],\n",
       "         [8.64951592e-01, 9.35199033e-01, 1.91872675e-01, ...,\n",
       "          4.49665642e-01, 1.22959920e-01, 8.86299345e-01],\n",
       "         [3.44746240e-01, 3.30822274e-01, 7.35070745e-01, ...,\n",
       "          9.38219030e-01, 6.05841106e-01, 8.40053835e-01],\n",
       "         ...,\n",
       "         [3.21817587e-01, 2.63309488e-01, 6.24651472e-01, ...,\n",
       "          9.35351836e-01, 5.94110799e-01, 2.39399704e-01],\n",
       "         [8.21674515e-01, 3.76911830e-01, 8.47952993e-02, ...,\n",
       "          2.95085042e-01, 8.44939348e-02, 7.08590988e-01],\n",
       "         [5.10117546e-02, 7.95088367e-01, 1.44369922e-02, ...,\n",
       "          6.10779191e-01, 3.96377396e-01, 2.24775160e-01]],\n",
       "\n",
       "        [[1.90945781e-01, 4.73471400e-01, 4.26449481e-01, ...,\n",
       "          5.62276921e-01, 6.01077312e-01, 2.46893414e-02],\n",
       "         [4.32004469e-01, 5.82923287e-01, 7.23287892e-01, ...,\n",
       "          4.50612596e-02, 7.38136679e-01, 5.74444696e-01],\n",
       "         [5.75327184e-01, 1.52748024e-01, 4.79432622e-01, ...,\n",
       "          1.22468953e-01, 4.30154331e-01, 5.73215830e-01],\n",
       "         ...,\n",
       "         [8.44362245e-01, 1.83168293e-01, 6.87554604e-01, ...,\n",
       "          8.92461962e-01, 4.16732609e-02, 6.07895875e-01],\n",
       "         [7.92569787e-01, 3.62892814e-01, 3.90007185e-01, ...,\n",
       "          8.77513218e-01, 9.20435181e-01, 2.73605914e-01],\n",
       "         [8.49541247e-01, 7.18410921e-01, 8.06423894e-01, ...,\n",
       "          7.58934671e-01, 9.60875248e-01, 2.09495870e-02]]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[:, 1: -1, 1: -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 96, 96, 192)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[:, 2: -2, 2: -2, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dream = model.input  #该张量用于保存生成的图像\n",
    "\n",
    "grads = K.gradients(loss, dream)[0]  #计算损失相对于梦境图像的梯度\n",
    "\n",
    "grads /= K.maximum(K.mean(K.abs(grads)), 1e-7) #将梯度标准化\n",
    "\n",
    "outputs = [loss, grads]\n",
    "fetch_loss_and_grads = K.function([dream], outputs)  #给定一张输出图像 设置一个Keras函数来获取损失值和梯度值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_loss_and_grads(x):\n",
    "    outs = fetch_loss_and_grads([x])\n",
    "    loss_value = outs[0]\n",
    "    grad_values = outs[1]\n",
    "    return loss_value, grad_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "该函数运行iterations次梯度上升\n",
    "\"\"\"\n",
    "def gradient_ascent(x, iterations, step, max_loss=None):\n",
    "    for i in range(iterations):\n",
    "        loss_value, grad_values = eval_loss_and_grads(x)\n",
    "        if max_loss is not None and loss_value > max_loss:\n",
    "            break\n",
    "        print('...Loss value at', i, ':', loss_value)\n",
    "        x += step * grad_values\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "\n",
    "def resize_img(img, size):\n",
    "    img = np.copy(img)\n",
    "    factors = (1,\n",
    "               float(size[0]) / img.shape[1],\n",
    "               float(size[1]) / img.shape[2],\n",
    "               1\n",
    "              )\n",
    "    return scipy.ndimage.zoom(img, factors, order=1)\n",
    "\n",
    "\"\"\"\n",
    "通用函数，将一个张量转换为有效图像\n",
    "\"\"\"\n",
    "def deprocess_image(x):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x = x.reshape((3, x.shape[2], x.shape[3]))\n",
    "        x = x.transpose((1, 2, 0))\n",
    "    else:\n",
    "        x = x.reshape((x.shape[1], x.shape[2], 3))\n",
    "    x /= 2.\n",
    "    x += 0.5\n",
    "    x *= 255\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n",
    "\n",
    "def save_img(img, fname):\n",
    "    pil_img = deprocess_image(np.copy(img))\n",
    "    scipy.misc.imsave(fname, pil_img)\n",
    "\n",
    "\"\"\"\n",
    "通用函数，用于打开图像、改变图像大小以及将图像格式转换为Inception V3模型能够处理的张量\n",
    "\"\"\"\n",
    "def preprocess_image(img_path):\n",
    "    img = image.load_img(img_path)\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = inception_v3.preprocess_input(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  (250, 375)\n",
      "shape:  (179, 267)\n",
      "Processing image shape (179, 267)\n",
      "...Loss value at 0 : 1.1681775\n",
      "...Loss value at 1 : 1.4419689\n",
      "...Loss value at 2 : 2.0733752\n",
      "...Loss value at 3 : 2.6974218\n",
      "...Loss value at 4 : 3.396371\n",
      "...Loss value at 5 : 4.09803\n",
      "...Loss value at 6 : 4.7792854\n",
      "...Loss value at 7 : 5.387398\n",
      "...Loss value at 8 : 5.9562354\n",
      "...Loss value at 9 : 6.623434\n",
      "...Loss value at 10 : 7.327145\n",
      "...Loss value at 11 : 7.907139\n",
      "...Loss value at 12 : 8.590636\n",
      "...Loss value at 13 : 9.485498\n",
      "Processing image shape (250, 375)\n",
      "...Loss value at 0 : 2.6431794\n",
      "...Loss value at 1 : 3.7386477\n",
      "...Loss value at 2 : 3.990149\n",
      "...Loss value at 3 : 5.176982\n",
      "...Loss value at 4 : 5.7929497\n",
      "...Loss value at 5 : 5.6096888\n",
      "...Loss value at 6 : 6.839927\n",
      "...Loss value at 7 : 7.2192755\n",
      "...Loss value at 8 : 7.9933596\n",
      "...Loss value at 9 : 8.696547\n",
      "...Loss value at 10 : 9.934326\n",
      "...Loss value at 11 : 9.352362\n",
      "Processing image shape (351, 525)\n",
      "...Loss value at 0 : 2.8533874\n",
      "...Loss value at 1 : 3.989983\n",
      "...Loss value at 2 : 4.0882916\n",
      "...Loss value at 3 : 5.5103793\n",
      "...Loss value at 4 : 5.466166\n",
      "...Loss value at 5 : 6.1840715\n",
      "...Loss value at 6 : 6.6388235\n",
      "...Loss value at 7 : 7.5411615\n",
      "...Loss value at 8 : 6.8222094\n",
      "...Loss value at 9 : 7.6550407\n",
      "...Loss value at 10 : 8.611347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:31: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n"
     ]
    }
   ],
   "source": [
    "step = 0.02   #梯度上升的步长\n",
    "num_octave = 3  #运行梯度上升的尺度个数\n",
    "octave_scale = 1.4  #两个尺度之间的大小比例\n",
    "iterations = 30  #在每个尺度上运行梯度上升的步数\n",
    "\n",
    "max_loss = 10.  #如果损失大于10，中断梯度上升过程，避免伪影\n",
    "\n",
    "base_image_path = 'creative_commons_elephant.jpg'  #图像路径\n",
    "\n",
    "img = preprocess_image(base_image_path)  #将基础图象加载成numpy数组\n",
    "\n",
    "original_shape = img.shape[1:3]     #准备一个由形状元组组成的列表，其定义了运行梯度上升的不同尺度\n",
    "successive_shapes = [original_shape]\n",
    "for i in range(1, num_octave):\n",
    "    shape = tuple([int(dim / (octave_scale ** i)) for dim in original_shape])\n",
    "    print('shape: ', shape)\n",
    "    successive_shapes.append(shape)\n",
    "\n",
    "successive_shapes = successive_shapes[::-1]  #将形状列表反转，变为升序\n",
    "\n",
    "original_img = np.copy(img)\n",
    "shrunk_original_img = resize_img(img, successive_shapes[0])  #将图像numpy数组的大小缩放到最小尺寸\n",
    "\n",
    "for shape in successive_shapes:\n",
    "    print('Processing image shape', shape)\n",
    "    img = resize_img(img, shape)   #将梦境图像放大\n",
    "    img = gradient_ascent(img,     #运行梯度上升过程，改变梦境图像\n",
    "                          iterations=iterations,\n",
    "                          step=step,\n",
    "                          max_loss=max_loss)\n",
    "    upscaled_shrunk_original_img = resize_img(shrunk_original_img, shape) #将原始图像的较小版本放大，它会变得像素化\n",
    "    same_size_original = resize_img(original_img, shape)  #在这个尺寸上计算原始图像的高质量版本\n",
    "    lost_detail = same_size_original - upscaled_shrunk_original_img  #二者的差别就是在放大过程中丢失的细节\n",
    "    \n",
    "    img += lost_detail  #将丢失的细节重新注入到梦境图像中\n",
    "    shrunk_original_img = resize_img(original_img, shape)\n",
    "    #save_img(img, fname='dream_at_scale_' + str(shape) + '.png')\n",
    "\n",
    "save_img(img, fname='final_dream.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(179, 267), (250, 375), (351, 525)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "successive_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 375)\n",
      "(179, 267)\n"
     ]
    }
   ],
   "source": [
    "#octave_scale = 1.4\n",
    "for i in range(1, num_octave):\n",
    "    temp = tuple([int(dim / (octave_scale ** i)) for dim in original_shape])\n",
    "    print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
